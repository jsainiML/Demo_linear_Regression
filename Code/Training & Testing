# In this section we have trained our model using gradient descent and back propogation with 200+ epochs


torch.manual_seed(99)
epochs = 210 # no of loop for the data 
loss_v = []
testl_v = []
epoch_c = []

# Training the model
for epoch in range(epochs):
  model_0.train()  # puts the model in training mode

  y_prediction = model_0(X_train) # we have inputed the trainning data to our Fw pass predicting 'y'

  loss = lossfn(y_prediction, y_train) # calculating loss brtween predicted - actual 
  
  optimizer.zero_grad() #Clears the gradient of parameters

  loss.backward() # perfrom Backpropogation based on loss observed

  optimizer.step() # update parameters on computed gradients

# Testing the Model
  model_0.eval() # puts the model in evaluation i.e. testing/validation set
  with torch.inference_mode():
     ytest_preds = model_0(X_test) # inputed the testing data to our Fw pass

     test_loss = lossfn(ytest_preds, y_test) # calculating loss
 
 
 ---------------------------------------------------------------
  # following section can we use to see the trend in loss fuctions

  if epoch % 10 == 0:
    epoch_c.append(epoch)
    loss_v.append(loss.detach().numpy())
    testl_v.append(test_loss.detach().numpy())
    print (f"Epoc: {epoch}, Loss: {loss},  test loss: {test_loss}") 
